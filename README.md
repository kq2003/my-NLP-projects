Here are my extracurricular NLP projects / researches over the past two years. 
- Kaggle: CommonLit - Evaluate Student Summaries: July 2023

  This is our code for training models for kaggle competition: CommonLit - Evaluate Student Summaries.

  We cleaned the data, identified important parameters, and first tried out
  different pretrained models' performances on the dataset. We later stacked multiple pretrained huggingface models by building a stacking theme ourselves
  to reach an ideal model performance. We kept track of our model performance by cross-validation.
  
- TNEWS model performance recreation: May - June 2023

   This is my first time working with NLP tasks. I trained four Bert variations for TNEWS classification task (to classify what category each news belong to): Bert, Albert, 
  Roberta, and Ernie. I kept changing hyperparameters and train-test-split ratio to finally reach ideal model performance.

  Performance bench marks: https://github.com/CLUEbenchmark/CLUE#tnews-%E5%A4%B4%E6%9D%A1%E6%96%B0%E9%97%BB%E5%88%86%E7%B1%BB-toutiao-news-classification-accuracy

- Datagood: Analyze survey responses from CRS (Community Resources for Science): Sep 2022
  
  - Project description: The main goal of this project is to help the Community Resources for Science (CRS) analyze survey data from 10+ years of surveys stored in CSV files, 
  possibly selecting only certain years to look at. CRS anticipates looking at 6-8 key questions: teachers who are newer vs more experienced; teachers from 3 different school   
  districts, teachers' level of confidence and amount of time spent on teaching science, etc. The primary reason for looking more into these key questions is to help CRS better 
  understand the trends and differentiations among these key questions.
  - My work: I am responsible for year 2008 and year 2015. I cleaned the datasets, find correlations between parameters, did multiple visualizations and compared the other analysis and visulazations of other years. We then assessed our assumptions at first, and reached conclusions.

  

  
